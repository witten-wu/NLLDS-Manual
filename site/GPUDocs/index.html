<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>GPUDocs - NLL-Manual</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "GPUDocs";
        var mkdocs_page_input_path = "GPUDocs.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> NLL-Manual
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">NLLDS</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">GPUDocs</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#workstation-summary">Workstation Summary</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#get-your-account">Get Your Account</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#if-you-are-new-to-linux">If you are new to Linux</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#for-windows-users">For Windows Users</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#connect-example-xshell">Connect Example (XShell)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#connect-example-xftp">Connect Example (XFtp)</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#for-linuxmaxos-users">For Linux/MaxOS Users</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#change-your-password-at-your-first-login">Change your password at your first login</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#package-installation">Package Installation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#run-your-programme-on-our-compute-nodes">Run your Programme on our Compute Nodes</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#check-the-resources">Check the resources</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#conda">Conda</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#tumx">Tumx</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#matlab">MATLAB</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#running-example-python">Running example (Python)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#running-example-matlab">Running example (MATLAB)</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#quick-reference">Quick Reference</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#contact">Contact</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#useful-links">Useful Links</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">NLL-Manual</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">GPUDocs</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="gpu-docs">GPU Docs</h1>
<p>Author: Yidu Wu</p>
<p>Last updated on June 17, 2024 by Yidu</p>
<p>Before using the workstation, if you have no experience in using clusters for computing, then we strongly recommend that you take a moment to read the contents of this manual.</p>
<h2 id="workstation-summary">Workstation Summary</h2>
<table>
<thead>
<tr>
<th>Computing Nodes</th>
<th>Detail</th>
<th>RAM</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>[1x] Intel Xeon w7-3455 2.50 GHz 24C/48T</td>
<td>502GB</td>
</tr>
<tr>
<td>GPU</td>
<td>[1x] NVIDIA RTX A6000</td>
<td>48GB</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Storage</th>
<th>Capacity</th>
<th>Disk</th>
<th>Mount</th>
</tr>
</thead>
<tbody>
<tr>
<td>KXG80ZN84T09 NVMe KIOXIA</td>
<td>4TB</td>
<td>/dev/nvme0n1</td>
<td>/ &amp; /home</td>
</tr>
<tr>
<td>PC SN810 NVMe WDC</td>
<td>2TB</td>
<td>/dev/nvme1n1</td>
<td>/SSData0</td>
</tr>
<tr>
<td>ST12000NM002J-2T</td>
<td>12TB</td>
<td>/dev/sda</td>
<td>/BigData0</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Other Configurations</th>
<th>Remark</th>
</tr>
</thead>
<tbody>
<tr>
<td>Network</td>
<td>1Gbps LAN connected to CUHK network</td>
</tr>
<tr>
<td>Operating System</td>
<td>Ubuntu 22.04 LTS</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Packages pre-installed</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python</td>
<td>3.10.12</td>
</tr>
<tr>
<td>MATLAB</td>
<td>R2024a</td>
</tr>
<tr>
<td>CUDA</td>
<td>12.0</td>
</tr>
<tr>
<td>cuDNN</td>
<td>8.9.7</td>
</tr>
<tr>
<td>Conda</td>
<td>24.1.2</td>
</tr>
<tr>
<td>GCC/G++</td>
<td>11.4.0</td>
</tr>
<tr>
<td>Cmake</td>
<td>3.22.1</td>
</tr>
<tr>
<td>Java</td>
<td>1.8</td>
</tr>
<tr>
<td>Git</td>
<td>2.34.1</td>
</tr>
<tr>
<td>Vim</td>
<td>8.2</td>
</tr>
<tr>
<td>Tmux</td>
<td>3.2a</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>IP</th>
<th>Port</th>
<th>User Type</th>
<th>Remark</th>
</tr>
</thead>
<tbody>
<tr>
<td>137.189.158.32</td>
<td>22</td>
<td>CUHK User</td>
<td>Off-campus user need connect CUHK VPN first</td>
</tr>
<tr>
<td>8.219.66.9</td>
<td>6000</td>
<td>Non-CUHK User</td>
<td>Forwarded by Aliyun, latency may exist</td>
</tr>
</tbody>
</table>
<!-- ```bash
+ ---------------------------------------------------------------------- +
| Workstation: Precision 7960 Tower (0A3A)                               |
+ ====================================================================== +
| Computing Power:                                                       |
| ---------------------------------------------------------------------- |
| Type    | Detail                                    | RAM              |
| ---------------------------------------------------------------------- |
| CPU     | [1x] Intel Xeon w7-3455 2.50 GHz 24C/48T  | 502GB            |
| GPU     | [1x] NVIDIA RTX A6000                     | 48GB             | 
+ ====================================================================== +
| Storage:                  | Capacity  | Disk          | Mount          |
| ---------------------------------------------------------------------- |                   
| KXG80ZN84T09 NVMe KIOXIA  | 4TB       | /dev/nvme0n1  | / & /home      |
| PC SN810 NVMe WDC         | 2TB       | /dev/nvme1n1  | /SSData0       |
| ST12000NM002J-2T          | 12TB      | /dev/sda      | /BigData0      |
+ ====================================================================== +
| Other Configurations:                                                  |
| ---------------------------------------------------------------------- | 
| Network                | 1Gbps LAN connected to CUHK network           |
| Operating System       | Ubuntu 22.04 LTS                              |
+ ---------------------------------------------------------------------- +

+ ---------------------------------------------------------------------- +
| Connectivity Entry:                                                    |
| ---------------------------------------------------------------------- |
| IP               | Port  | User Type      | Remark                     |
| ---------------------------------------------------------------------- |  
| 137.189.158.26   | 22    | CUHK User      | Off-campus user need VPN   |
| 8.219.66.9       | 6000  | Non-CUHK User  | Aliyun forwarding          |
+ ---------------------------------------------------------------------- +

+ ---------------------------------+
| Packages pre-installed:          |
| -------------------------------- |  
| Python 3.10.12                   |
| CUDA 12.0                        |
| cuDNN 8.9.7                      |
| Conda 24.1.2                     |
| GCC/G++ 11.4.0                   |
| Cmake 3.22.1                     |
| Java 1.8                         |
| Git 2.34.1                       |
| Vim 8.2                          |
| Tmux 3.2a                        |
+ ---------------------------------+
``` -->

<h2 id="getting-started">Getting Started</h2>
<p>This page gives minimum information to run a program on our computing cluster. If you are using the cluster for the first time, you should read this page carefully.</p>
<h3 id="get-your-account">Get Your Account</h3>
<p>Before you use the cluster, you should apply an account from our administrators. Please send an email to Yidu Wu (<a href="mailto:yiduwu@cuhk.edu.hk">yiduwu@cuhk.edu.hk</a>) with your <strong>name</strong>, <strong>position</strong>, and <strong>expected study years (for students)</strong>.</p>
<h3 id="if-you-are-new-to-linux">If you are new to Linux</h3>
<p>Unfortunately, our cluster is running Linux operating system. If you have never used Linux before, it may be pretty uncomfortable for you to use a new operating system by command line but not GUI. We understand your feeling, but please try to get familiar with Linux commands on a virtual machine before moving on.</p>
<p>The following document assumes you have experience with Linux.</p>
<h3 id="for-windows-users">For Windows Users</h3>
<p>To access a Linux server on Windows, you need to install software through <strong>SSH</strong> and <strong>SFTP</strong>. You can try out the following software.</p>
<ul>
<li>SSH Client (For Command Line): <a href="https://mobaxterm.mobatek.net/">MobaXterm</a>, <a href="https://www.netsarang.com/en/xshell/">XShell (Recommand)</a></li>
<li>SFTP Client (For File Upload): <a href="https://mobaxterm.mobatek.net/">MobaXterm</a>, <a href="https://www.netsarang.com/en/xftp/">Xftp (Recommand)</a>, <a href="https://filezilla-project.org/">FileZilla</a></li>
</ul>
<p>Here is the URL to download <code>Xshell</code> and <code>Xftp</code>: https://www.netsarang.com/en/free-for-home-school/ . Please note that this is free, no purchase required.</p>
<h4 id="connect-example-xshell">Connect Example (XShell)</h4>
<p>After installation we run Xshell, the first thing we need to do is to create a new session to connect to our cluster. Here is the configuration:</p>
<ul>
<li><code>Protocal</code>: SSH</li>
<li><code>Host</code>: IP Address (Reference Workstation Summary)</li>
<li><code>Port</code>: Port (Reference Workstation Summary) </li>
</ul>
<p><img alt="" src="../img/Xshell1.png" /></p>
<p>After that, click <code>Connect</code> button and enter your username with password.</p>
<p><img alt="" src="../img/Xshell2.png" /></p>
<p><img alt="" src="../img/Xshell3.png" /></p>
<p>After connected, you can start executing your command now! Please note that each user will have their own home dir, as shown in the picture, <code>/home/&lt;your_username&gt;</code> is your home path. You can run your program and upload your files here. </p>
<p><img alt="" src="../img/Xshell4.png" /></p>
<h4 id="connect-example-xftp">Connect Example (XFtp)</h4>
<p>Similar to above, we run XFtp and make the configuration.</p>
<ul>
<li><code>Host</code>: IP Address (Reference Workstation Summary)</li>
<li><code>Protocal</code>: SFTP</li>
<li><code>Port</code>: Port (Reference Workstation Summary) </li>
<li><code>Method</code>: Password</li>
</ul>
<p>Enter your username with password and click connect button.</p>
<p><img alt="" src="../img/XFtp1.png" /></p>
<p>After connected, The left panel is your local file system and the right is the remote. You can now upload and download files as you like. </p>
<p><img alt="" src="../img/XFtp2.png" /></p>
<p>Please make sure that you only upload files to these three paths, which you have the full access:</p>
<ul>
<li><code>/home/&lt;your_username&gt;</code>: Your home dir (50GB quota, Ask me for more space If quota exceeded)</li>
<li><code>/BigData0</code>: Extra Disk (Reference Workstation Summary) (please store your large files here)</li>
<li><code>/SSData0</code>: Extra Disk (Reference Workstation Summary) (use it when /BigData0 disk full)</li>
</ul>
<h3 id="for-linuxmaxos-users">For Linux/MaxOS Users</h3>
<p>The cluster can log through <code>SSH</code>. On Linux or macOS terminal, input the following command to login.</p>
<pre><code class="language-bash">$ ssh &lt;username&gt;@&lt;ip&gt; -p &lt;port&gt;
</code></pre>
<p>After a successful connection, the server will prompt you to enter a password. Please enter the password which you got from administrators at this time. There will be no response on the interface when you enter the password, but the password has already been entered.</p>
<h3 id="change-your-password-at-your-first-login">Change your password at your first login</h3>
<p>An initial password was sent to each user for their first-time-login. For security reason, please change your password with:</p>
<pre><code class="language-bash">$ passwd
</code></pre>
<h3 id="package-installation">Package Installation</h3>
<p>Please note that for security reasons, all users do not have <code>sudo</code> permissions by default. It means that you cannot install the required packages by raising to <code>root</code> privileges with the <code>sudo</code> command! Nevertheless, you can still install the packages you need by the way of compiling the source code, although this will take some effort and requires some expertise in linux. Alternatively, you can contact the administrator to install the packages for you.</p>
<h3 id="run-your-programme-on-our-compute-nodes">Run your Programme on our Compute Nodes</h3>
<p>Since we only have 1 GPU right now, we are holding off on using e.g. SLURM resource management software to manage our cluster. Instead of it, at this stage we consider a negotiated allocation to use our compute nodes. An easy way to do this is to book it directly in the DingTalk calendar! Before using the cluster you should organize your schedule ahead of time and add it to our DingTalk calendar, making sure not to cross over with other people's schedules. Please use computing nodes strictly according to the calendar schedule. If there are indeed urgent tasks that need to be prioritized, please negotiate with the user who owns the current schedule.</p>
<h4 id="check-the-resources">Check the resources</h4>
<p>Before running the program, check the GPU to ensure there are sufficient computing resources, input the following command.</p>
<pre><code class="language-bash">$ nvidia-smi
</code></pre>
<p>And it will output:</p>
<pre><code class="language-bash">+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000               Off | 00000000:AC:00.0 Off |                  Off |
| 30%   32C    P8              12W / 300W |    308MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1995      G   /usr/lib/xorg/Xorg                          180MiB |
|    0   N/A  N/A      2143      G   /usr/bin/gnome-shell                         47MiB |
+---------------------------------------------------------------------------------------+
</code></pre>
<p>You can see the relevant parameters of the GPU, such as model, CUDA version, memory usage, etc. In this case, The <code>308MiB / 49140MiB</code> stands for 'used/total memory', make sure there is enough memory for you to use! You can also see all processes that are taking up memory, and if you make sure that a process doesn't need to run anymore, you can kill it to free up memory. But be careful not to kill programs that other users may be running!</p>
<h4 id="conda">Conda</h4>
<p>First thing first, whenever you create a new python project, the most important step is setting up the python interpreter. Using the python interpreter of your virtual enviornment is recommended, which can separate the develop enviroments for each of your project.</p>
<p><code>Conda</code> is officially recommended by PyTorch and TensorFlow. Here’s some <code>conda</code> command:</p>
<pre><code class="language-bash"># create conda env with python (you can specify python version)
conda create --name &lt;new-env-name&gt; python=3.8
# check envs
conda env list
# activate env
conda activate &lt;env-name&gt;
# deactivate env
conda deactivate
# install package like pandas
conda install pandas
</code></pre>
<h4 id="tumx">Tumx</h4>
<p>If you only use ssh to connect to the server to run the program, the program will be shut down as soon as ssh breaks (Even if you don't end it manually, ssh will often break unexpectedly due to network problems). The solution is to use tmux to open a session and run it in the background, even if ssh breaks, tmux server will still keep that session for you, so the program will always run in the background.</p>
<p>Start a background terminal session using <code>tmux</code>.Simply run <code>tmux</code>, you can get a new session. After run the job, press <code>Ctrl+B D</code> shortcut to detach the session. When you return, use <code>tmux ls</code> to see the session ID, then use <code>tmux a -t &lt;ID&gt;</code> to attach the session and continue the job.</p>
<h4 id="matlab">MATLAB</h4>
<p>All of the above assumes you are using the python; if you are a MATLAB user, please read the following carefully.</p>
<p>We have already pre-installed the MATLAB (R2024a) in our cluster. Unfortunately, we are unable to share MATLAB licences within the cluster due to MATLAB's strict licensing requirements. And it's also not possible to sign in with multiple user accounts on the same server instance, whether it's a real or virtual server. This means that only one user is allowed to use MATLAB in our cluster at any given time, and if other users need to use it they need to queue up, so I recommend that you schedule a MATLAB appointment in our DingTalk calendar just like GPU before.</p>
<p>I recommend using the MATLAB resources in our cluster only when you need to use the GPU to assist in computing MATLAB program, because in this way the occupancy time of MATLAB is consistent with the occupancy time of the GPU. For other tasks, you can do it on your own computer with CPU.</p>
<p>Nevertheless, you can still use it without restriction by installing a separate MATLAB program in your own home dir. This assumes that you have a MATLAB licence and you can activate it with your own licence. </p>
<p><strong>Instructions for using our pre-installed MATLAB:</strong></p>
<p>Before using it you should get the username/password of our MATLAB user from the administrator, please note that this is a separate LINUX user which only used to run MATLAB. Please make sure to plan your time well and don’t take up too much time or conflict with others.</p>
<p>Please note that if you need to install any third-party tools, please contact the administrator!</p>
<p>Please also note that the pre-installed MATLAB in our cluster is tied to our administrator's licence. If you encounter MATLAB updates or verifications from time to time, please contact administrator for assistance.</p>
<p>We will give a running example of MATLAB below.</p>
<h4 id="running-example-python">Running example (Python)</h4>
<p>Here I will show you an example to run python programme.</p>
<ul>
<li>Suppose we want to execute the following Python code, which is the multiplication of two matrix of 10240 x 10240 dimensions:</li>
</ul>
<pre><code class="language-bash">import numpy as np
import cupy as cp
import time

# Generate matrix on the CPU
A = np.random.rand(10240, 10240).astype(np.float32)
B = np.random.rand(10240, 10240).astype(np.float32)

# Copy matrix to GPU memory
A_gpu = cp.array(A)
B_gpu = cp.array(B)

# CPU function 
def cpu_matrix_mul(A, B):
    return np.matmul(A, B)

# GPU function
def gpu_matrix_mul(A, B):
    return cp.matmul(A, B)

# Test CPU Running time
start = time.time()
C_cpu = cpu_matrix_mul(A, B)
cpu_time = time.time() - start
print(f&quot;CPU time consumption: {cpu_time:.6f} second&quot;)

# Test GPU Running time
start = time.time()
C_gpu = gpu_matrix_mul(A_gpu, B_gpu)
gpu_time = time.time() - start
print(f&quot;GPU time consumption: {gpu_time:.6f} second&quot;)
</code></pre>
<ul>
<li>
<p>The first thing we need to do is to upload this python file to our GPU cluster, We've already covered how to upload files with XFtp earlier on.</p>
</li>
<li>
<p>Supposed I have already uploaded the python file to my home path. Now we can check it.</p>
</li>
</ul>
<p><img alt="" src="../img/Xshell5.png" /></p>
<p>We can see the test.py under my home dir. Now use <code>vi test.py</code> to view the file content.</p>
<p><img alt="" src="../img/Xshell6.png" /></p>
<ul>
<li>If there is no problem, we can prepare to run the code. Excute the following command to create a virtual enviornment for python.</li>
</ul>
<pre><code class="language-bash">conda create --name gputest python=3.9
</code></pre>
<p>Learn to use conda to separate the develop enviroments for each of your project is very important.</p>
<p>After that, excute command <code>tmux</code> and we will get a new window like this:</p>
<p><img alt="" src="../img/Xshell7.png" /></p>
<p>Tumx can make the program always run in the background even if you exit the ssh. </p>
<p>Now we need to activate the virtual python environment created before, like this:</p>
<p><img alt="" src="../img/Xshell8.png" /></p>
<p>We can find our python environment has changed from base to <code>gputest</code>.</p>
<ul>
<li>install the packages required.</li>
</ul>
<pre><code class="language-bash">conda install numpy
conda install -c conda-forge cupy
</code></pre>
<ol>
<li>Then we run the GPU python code, we can find that the GPU is much faster than the CPU.</li>
</ol>
<p><img alt="" src="../img/Xshell9.png" /></p>
<h4 id="running-example-matlab">Running example (MATLAB)</h4>
<p>Here I will show you an example to run MATLAB programme.</p>
<ul>
<li>Suppose we want to execute the following matrix multiplication MATLAB code:</li>
</ul>
<pre><code class="language-bash">% Generate matrix on the CPU
A = rand(10240, 10240, 'single');
B = rand(10240, 10240, 'single');

% Copy matrix to GPU memory
A_gpu = gpuArray(A);
B_gpu = gpuArray(B);

% CPU function
function C = cpu_matrix_mul(A, B)
    C = A * B;
end

% GPU function
function C = gpu_matrix_mul(A, B)
    C = gather(A * B);
end

% Test CPU Running time
tic;
C_cpu = cpu_matrix_mul(A, B);
cpu_time = toc;
fprintf(&quot;CPU time consumption: %.6f seconds\n&quot;, cpu_time);

% Test GPU Running time
tic;
C_gpu = gpu_matrix_mul(A_gpu, B_gpu);
gpu_time = toc;
fprintf(&quot;GPU time consumption: %.6f seconds\n&quot;, gpu_time);
</code></pre>
<ul>
<li>Login to our cluster as a MATLAB user. You can switch to it by command <code>su matlab</code>. Then type the password got from our administrator.</li>
</ul>
<p><img alt="" src="../img/Xshell10.png" /></p>
<ul>
<li>Then upload the MATLAB file to this home dir. In this case, I have uploaded it under Desktop folder.</li>
</ul>
<p><img alt="" src="../img/Xshell11.png" /></p>
<ul>
<li>Then run the <code>matlab</code> command directly to start matlab, which we set to start from the command line by default. And the we can execute our GPU test programme like this:</li>
</ul>
<p><img alt="" src="../img/Xshell12.png" /></p>
<p>Then we can see the resuls.</p>
<p><strong>Now you should know how to run your programme in our cluster.</strong></p>
<h2 id="quick-reference">Quick Reference</h2>
<h3 id="contact">Contact</h3>
<p>The computing cluster and the storage server are managed by Yidu Wu (<a href="mailto:yiduwu@cuhk.edu.hk">yiduwu@cuhk.edu.hk</a>).</p>
<h3 id="useful-links">Useful Links</h3>
<ul>
<li>CUHK VPN: <a href="https://www.itsc.cuhk.edu.hk/all-it/wifi-and-network/cuhk-vpn/">https://www.itsc.cuhk.edu.hk/all-it/wifi-and-network/cuhk-vpn/</a></li>
<li>Conda User Guide: <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/index.html">https://docs.conda.io/projects/conda/en/latest/user-guide/index.html</a></li>
<li>Tmux User Guide: <a href="https://hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/">https://hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/</a></li>
<li>Linux Command Guide: <a href="http://www.linuxcommand.org/tlcl.php/tlcl.php">http://www.linuxcommand.org/tlcl.php/tlcl.php</a></li>
<li>MATLAB Installation Guide: <a href="https://ww2.mathworks.cn/matlabcentral/answers/98886-how-do-i-install-matlab-and-its-toolboxes">https://ww2.mathworks.cn/matlabcentral/answers/98886-how-do-i-install-matlab-and-its-toolboxes</a></li>
<li>MATLAB GPU Guide: <a href="https://ww2.mathworks.cn/help/parallel-computing/gpu-computing-requirements.html">https://ww2.mathworks.cn/help/parallel-computing/gpu-computing-requirements.html</a></li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href=".." class="btn btn-neutral float-left" title="NLLDS"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href=".." style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
